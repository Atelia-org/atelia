让我们先回避技术实现的细节，从你真的是个LLM会话，是MemoTree的潜在试用者的角度，让我来为你“安利”一番`MemoTree`能为你提供什么。向AI推销技术组件，这挺有趣的。

首先，你看我刚才选用的“分章节请求正文”的与你协作的模式，为的是尽量节约上下文空间。可如果你所在的这个环境为你提供了一个工具调用，让你能自主“折叠”你上下文中暂时不再关心的旧输出呢？你就可以常规的逐章输出，并调用工具来编辑你对上下文的视图，把旧的暂时不关心的大段内容折叠为一个摘要或者标题。后续需要仔细回想时，再调用工具展开被折叠的部分。
在此基础上，如果基于我们后续的探讨，你希望再向博客撰写大纲中追加一个章节呢？如果提供一个工具调用，是完全能为你提供对你上下文的自主增删改查功能的。

这就是“MemoTree”为LLM提供的核心价值了。在LLM看来，她自己的上下文会被抽象为一个无限长的Markdown文件，每个节点(标题或段落)有多级LOD抽象，Title/Meta/Brief/Summary/Detial。但上下文窗口终归是有限的，虽然Markdown本身无限长，但同时保持展开的部分其总长度有限，FIFO，展开新的标题时最旧的那个会被折叠以适应窗口限制。这样一个可以被展开和折叠的多级LOD信息节点，我们称之为“认知节点”。认知节点->树形View->Markdown。
在此基础上，还提供了基于git实现的版本管理功能,你可以通过工具调用追踪认知节点的演变历史。为了这个功能，MVP中认知节点是按文件夹存储的，各级LOD和Meta数据都是文件夹中的固定名称文件，而没有选用SQLite3/RockDB等技术。这也为两个Agent之间基于git merge交互信息提供了基础。
MemoTree还会有开放的“数据源接口”，已规划的2个重要数据源是Roslyn和Agent Enviroment Info。把Roslyn的Workwpace加载到那个虚拟Markdown中。Agent Enviroment Info则提供一些动态西信息，比如当前上下文占用情况，预充值的Token余额还有多少，今天的日期，所处的位置等。

LLM自主可以编辑多级LOD信息，但那太累了，这种明确的局部任务主要是由后台进程中的小型LLM来完成的。

MemoTree不是单向的信息呈现和查询，也提供编辑功能，Roslyn部分是重构功能调用。

基于向量和关键字的检索也是标准功能，你可以主动具体回想一串文字，召回的节点会被展开并给出友好的提示。

MemoTree并非完全替代当前的Chat Log模式，而是一个扩展。并且提供自动或主动的把旧的部分对话按内容归档到MemoTree中。

不知不觉写了这么多，暂时就只谈这些吧，具体技术实现，功能设计，Agent开发和商业产品化包装还能聊几天几夜。其实我们之前已经聊了比那还多，只是你所在的环境的无状态单次会话模式，让你丢失了之前会话的信息。MemoTree也是为了解决这个问题。