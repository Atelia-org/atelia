{
  "investigation_summary": {
    "context": "MemoTree is a cognitive context management system for LLM agents.",
    "bos_token_detected": true,
    "avg_bos_ratio_last_layer": 0.7081298828125,
    "max_bos_ratio_last_layer": 0.76513671875
  },
  "bos_analysis": {
    "context": "MemoTree is a cognitive context management system for LLM agents.",
    "context_tokens": [
      "<|begin_of_text|>",
      "Memo",
      "Tree",
      "Ġis",
      "Ġa",
      "Ġcognitive",
      "Ġcontext",
      "Ġmanagement",
      "Ġsystem",
      "Ġfor",
      "ĠL",
      "LM",
      "Ġagents",
      "."
    ],
    "bos_token_index": 0,
    "generation_steps": [
      {
        "step": 0,
        "generated_token": "ĠIt",
        "bos_attention_by_layer": [
          0.66552734375,
          0.82373046875,
          0.892578125,
          0.83056640625,
          0.755859375,
          0.79736328125,
          0.6962890625,
          0.66015625,
          0.6181640625,
          0.67041015625,
          0.734375,
          0.50048828125,
          0.64794921875,
          0.671875,
          0.61083984375,
          0.6650390625,
          0.724609375,
          0.78173828125,
          0.76513671875,
          0.84375,
          0.80615234375,
          0.8037109375,
          0.818359375,
          0.77587890625,
          0.7607421875,
          0.85791015625,
          0.611328125,
          0.67138671875
        ],
        "total_attention_by_layer": [
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0
        ],
        "bos_attention_ratio_by_layer": [
          0.66552734375,
          0.82373046875,
          0.892578125,
          0.83056640625,
          0.755859375,
          0.79736328125,
          0.6962890625,
          0.66015625,
          0.6181640625,
          0.67041015625,
          0.734375,
          0.50048828125,
          0.64794921875,
          0.671875,
          0.61083984375,
          0.6650390625,
          0.724609375,
          0.78173828125,
          0.76513671875,
          0.84375,
          0.80615234375,
          0.8037109375,
          0.818359375,
          0.77587890625,
          0.7607421875,
          0.85791015625,
          0.611328125,
          0.67138671875
        ]
      },
      {
        "step": 1,
        "generated_token": "Ġenables",
        "bos_attention_by_layer": [
          0.71923828125,
          0.830078125,
          0.8681640625,
          0.7587890625,
          0.6484375,
          0.736328125,
          0.615234375,
          0.556640625,
          0.51318359375,
          0.52392578125,
          0.65283203125,
          0.568359375,
          0.54443359375,
          0.6015625,
          0.5810546875,
          0.62255859375,
          0.77294921875,
          0.83544921875,
          0.767578125,
          0.77294921875,
          0.84130859375,
          0.91845703125,
          0.9052734375,
          0.7529296875,
          0.86962890625,
          0.85791015625,
          0.70556640625,
          0.7373046875
        ],
        "total_attention_by_layer": [
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0
        ],
        "bos_attention_ratio_by_layer": [
          0.71923828125,
          0.830078125,
          0.8681640625,
          0.7587890625,
          0.6484375,
          0.736328125,
          0.615234375,
          0.556640625,
          0.51318359375,
          0.52392578125,
          0.65283203125,
          0.568359375,
          0.54443359375,
          0.6015625,
          0.5810546875,
          0.62255859375,
          0.77294921875,
          0.83544921875,
          0.767578125,
          0.77294921875,
          0.84130859375,
          0.91845703125,
          0.9052734375,
          0.7529296875,
          0.86962890625,
          0.85791015625,
          0.70556640625,
          0.7373046875
        ]
      },
      {
        "step": 2,
        "generated_token": "Ġthe",
        "bos_attention_by_layer": [
          0.65576171875,
          0.8154296875,
          0.9033203125,
          0.80126953125,
          0.78466796875,
          0.81982421875,
          0.7587890625,
          0.6484375,
          0.59326171875,
          0.68017578125,
          0.6279296875,
          0.64453125,
          0.57861328125,
          0.59619140625,
          0.6044921875,
          0.64697265625,
          0.70263671875,
          0.80126953125,
          0.7265625,
          0.72314453125,
          0.81298828125,
          0.86474609375,
          0.88623046875,
          0.75927734375,
          0.8525390625,
          0.84619140625,
          0.6171875,
          0.744140625
        ],
        "total_attention_by_layer": [
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0
        ],
        "bos_attention_ratio_by_layer": [
          0.65576171875,
          0.8154296875,
          0.9033203125,
          0.80126953125,
          0.78466796875,
          0.81982421875,
          0.7587890625,
          0.6484375,
          0.59326171875,
          0.68017578125,
          0.6279296875,
          0.64453125,
          0.57861328125,
          0.59619140625,
          0.6044921875,
          0.64697265625,
          0.70263671875,
          0.80126953125,
          0.7265625,
          0.72314453125,
          0.81298828125,
          0.86474609375,
          0.88623046875,
          0.75927734375,
          0.8525390625,
          0.84619140625,
          0.6171875,
          0.744140625
        ]
      },
      {
        "step": 3,
        "generated_token": "ĠL",
        "bos_attention_by_layer": [
          0.64892578125,
          0.822265625,
          0.9072265625,
          0.80224609375,
          0.80078125,
          0.7275390625,
          0.6552734375,
          0.61279296875,
          0.572265625,
          0.62109375,
          0.65673828125,
          0.662109375,
          0.62939453125,
          0.6123046875,
          0.61474609375,
          0.64404296875,
          0.7158203125,
          0.81201171875,
          0.724609375,
          0.70166015625,
          0.80859375,
          0.86083984375,
          0.87890625,
          0.72802734375,
          0.8115234375,
          0.82861328125,
          0.62353515625,
          0.662109375
        ],
        "total_attention_by_layer": [
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0
        ],
        "bos_attention_ratio_by_layer": [
          0.64892578125,
          0.822265625,
          0.9072265625,
          0.80224609375,
          0.80078125,
          0.7275390625,
          0.6552734375,
          0.61279296875,
          0.572265625,
          0.62109375,
          0.65673828125,
          0.662109375,
          0.62939453125,
          0.6123046875,
          0.61474609375,
          0.64404296875,
          0.7158203125,
          0.81201171875,
          0.724609375,
          0.70166015625,
          0.80859375,
          0.86083984375,
          0.87890625,
          0.72802734375,
          0.8115234375,
          0.82861328125,
          0.62353515625,
          0.662109375
        ]
      },
      {
        "step": 4,
        "generated_token": "LM",
        "bos_attention_by_layer": [
          0.615234375,
          0.826171875,
          0.8603515625,
          0.8681640625,
          0.8076171875,
          0.6787109375,
          0.63818359375,
          0.6015625,
          0.50537109375,
          0.560546875,
          0.57958984375,
          0.662109375,
          0.6865234375,
          0.58642578125,
          0.7021484375,
          0.72265625,
          0.78271484375,
          0.8486328125,
          0.7841796875,
          0.87060546875,
          0.9248046875,
          0.95556640625,
          0.9013671875,
          0.86083984375,
          0.84912109375,
          0.84912109375,
          0.73388671875,
          0.6474609375
        ],
        "total_attention_by_layer": [
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0
        ],
        "bos_attention_ratio_by_layer": [
          0.615234375,
          0.826171875,
          0.8603515625,
          0.8681640625,
          0.8076171875,
          0.6787109375,
          0.63818359375,
          0.6015625,
          0.50537109375,
          0.560546875,
          0.57958984375,
          0.662109375,
          0.6865234375,
          0.58642578125,
          0.7021484375,
          0.72265625,
          0.78271484375,
          0.8486328125,
          0.7841796875,
          0.87060546875,
          0.9248046875,
          0.95556640625,
          0.9013671875,
          0.86083984375,
          0.84912109375,
          0.84912109375,
          0.73388671875,
          0.6474609375
        ]
      },
      {
        "step": 5,
        "generated_token": "Ġto",
        "bos_attention_by_layer": [
          0.70849609375,
          0.8095703125,
          0.87255859375,
          0.9130859375,
          0.82470703125,
          0.7783203125,
          0.7626953125,
          0.6826171875,
          0.468994140625,
          0.6767578125,
          0.5986328125,
          0.701171875,
          0.712890625,
          0.62109375,
          0.61572265625,
          0.69091796875,
          0.79052734375,
          0.85107421875,
          0.82275390625,
          0.7744140625,
          0.85498046875,
          0.8603515625,
          0.88916015625,
          0.751953125,
          0.79345703125,
          0.826171875,
          0.59130859375,
          0.69189453125
        ],
        "total_attention_by_layer": [
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          0.99951171875,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0
        ],
        "bos_attention_ratio_by_layer": [
          0.70849609375,
          0.8095703125,
          0.87255859375,
          0.9130859375,
          0.82470703125,
          0.7783203125,
          0.7626953125,
          0.6826171875,
          0.468994140625,
          0.6767578125,
          0.5986328125,
          0.701171875,
          0.712890625,
          0.62109375,
          0.6162109375,
          0.69091796875,
          0.79052734375,
          0.85107421875,
          0.82275390625,
          0.7744140625,
          0.85498046875,
          0.8603515625,
          0.88916015625,
          0.751953125,
          0.79345703125,
          0.826171875,
          0.59130859375,
          0.69189453125
        ]
      },
      {
        "step": 6,
        "generated_token": "Ġmaintain",
        "bos_attention_by_layer": [
          0.6318359375,
          0.76904296875,
          0.853515625,
          0.76416015625,
          0.7578125,
          0.6572265625,
          0.58642578125,
          0.5146484375,
          0.50830078125,
          0.456787109375,
          0.615234375,
          0.541015625,
          0.57275390625,
          0.49658203125,
          0.5341796875,
          0.63330078125,
          0.79248046875,
          0.85107421875,
          0.7880859375,
          0.73974609375,
          0.84619140625,
          0.91650390625,
          0.9140625,
          0.77099609375,
          0.87109375,
          0.84521484375,
          0.7021484375,
          0.74560546875
        ],
        "total_attention_by_layer": [
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          0.99951171875,
          1.0,
          1.0,
          1.0
        ],
        "bos_attention_ratio_by_layer": [
          0.6318359375,
          0.76904296875,
          0.853515625,
          0.76416015625,
          0.7578125,
          0.6572265625,
          0.58642578125,
          0.5146484375,
          0.50830078125,
          0.456787109375,
          0.615234375,
          0.541015625,
          0.57275390625,
          0.49658203125,
          0.5341796875,
          0.63330078125,
          0.79248046875,
          0.85107421875,
          0.7880859375,
          0.73974609375,
          0.84619140625,
          0.91650390625,
          0.9140625,
          0.77099609375,
          0.87158203125,
          0.84521484375,
          0.7021484375,
          0.74560546875
        ]
      },
      {
        "step": 7,
        "generated_token": "Ġa",
        "bos_attention_by_layer": [
          0.72119140625,
          0.8095703125,
          0.90234375,
          0.80517578125,
          0.81982421875,
          0.74951171875,
          0.75048828125,
          0.63427734375,
          0.58251953125,
          0.6171875,
          0.5859375,
          0.619140625,
          0.5634765625,
          0.5546875,
          0.6328125,
          0.63232421875,
          0.802734375,
          0.865234375,
          0.7763671875,
          0.74462890625,
          0.82373046875,
          0.8955078125,
          0.89990234375,
          0.80810546875,
          0.849609375,
          0.85498046875,
          0.6826171875,
          0.76513671875
        ],
        "total_attention_by_layer": [
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0
        ],
        "bos_attention_ratio_by_layer": [
          0.72119140625,
          0.8095703125,
          0.90234375,
          0.80517578125,
          0.81982421875,
          0.74951171875,
          0.75048828125,
          0.63427734375,
          0.58251953125,
          0.6171875,
          0.5859375,
          0.619140625,
          0.5634765625,
          0.5546875,
          0.6328125,
          0.63232421875,
          0.802734375,
          0.865234375,
          0.7763671875,
          0.74462890625,
          0.82373046875,
          0.8955078125,
          0.89990234375,
          0.80810546875,
          0.849609375,
          0.85498046875,
          0.6826171875,
          0.76513671875
        ]
      }
    ]
  },
  "distribution_analysis": {
    "context": "MemoTree is a cognitive context management system for LLM agents.",
    "context_tokens": [
      "<|begin_of_text|>",
      "Memo",
      "Tree",
      "Ġis",
      "Ġa",
      "Ġcognitive",
      "Ġcontext",
      "Ġmanagement",
      "Ġsystem",
      "Ġfor",
      "ĠL",
      "LM",
      "Ġagents",
      "."
    ],
    "num_layers": 28,
    "layer_analysis": [
      {
        "layer": 0,
        "attention_entropy": [
          -0.0,
          0.235107421875,
          0.51953125,
          0.69384765625,
          0.9384765625,
          0.65478515625,
          0.9580078125,
          0.93505859375,
          1.115234375,
          1.2568359375,
          1.3046875,
          1.046875,
          1.1884765625,
          1.4560546875
        ],
        "bos_attention_strength": [
          1.0,
          0.93701171875,
          0.84326171875,
          0.8095703125,
          0.7294921875,
          0.8515625,
          0.7470703125,
          0.7685546875,
          0.71875,
          0.6884765625,
          0.6845703125,
          0.755859375,
          0.73681640625,
          0.66552734375
        ],
        "attention_concentration": [
          1.0,
          0.93701171875,
          0.84326171875,
          0.8095703125,
          0.7294921875,
          0.8515625,
          0.7470703125,
          0.7685546875,
          0.71875,
          0.6884765625,
          0.6845703125,
          0.755859375,
          0.73681640625,
          0.66552734375
        ]
      },
      {
        "layer": 1,
        "attention_entropy": [
          -0.0,
          0.1309814453125,
          0.385986328125,
          0.45556640625,
          0.58935546875,
          0.56787109375,
          0.638671875,
          0.82080078125,
          0.87109375,
          0.9326171875,
          0.66796875,
          0.71875,
          0.88671875,
          0.892578125
        ],
        "bos_attention_strength": [
          1.0,
          0.97119140625,
          0.8955078125,
          0.892578125,
          0.861328125,
          0.875,
          0.8515625,
          0.7890625,
          0.79345703125,
          0.79443359375,
          0.86572265625,
          0.8466796875,
          0.81591796875,
          0.82373046875
        ],
        "attention_concentration": [
          1.0,
          0.97119140625,
          0.8955078125,
          0.892578125,
          0.861328125,
          0.875,
          0.8515625,
          0.7890625,
          0.79345703125,
          0.79443359375,
          0.86572265625,
          0.8466796875,
          0.81591796875,
          0.82373046875
        ]
      },
      {
        "layer": 2,
        "attention_entropy": [
          -0.0,
          0.09014892578125,
          0.143798828125,
          0.25830078125,
          0.344482421875,
          0.3076171875,
          0.319091796875,
          0.30322265625,
          0.460693359375,
          0.4755859375,
          0.395751953125,
          0.45361328125,
          0.53369140625,
          0.6015625
        ],
        "bos_attention_strength": [
          1.0,
          0.98193359375,
          0.97216796875,
          0.94775390625,
          0.9296875,
          0.943359375,
          0.9423828125,
          0.94677734375,
          0.91552734375,
          0.91357421875,
          0.9326171875,
          0.92138671875,
          0.90576171875,
          0.892578125
        ],
        "attention_concentration": [
          1.0,
          0.98193359375,
          0.97216796875,
          0.94775390625,
          0.9296875,
          0.943359375,
          0.9423828125,
          0.94677734375,
          0.91552734375,
          0.91357421875,
          0.9326171875,
          0.92138671875,
          0.90576171875,
          0.892578125
        ]
      },
      {
        "layer": 3,
        "attention_entropy": [
          -0.0,
          0.1907958984375,
          0.2578125,
          0.477783203125,
          0.55126953125,
          0.52587890625,
          0.63037109375,
          0.57080078125,
          0.8994140625,
          0.84228515625,
          0.75830078125,
          0.474365234375,
          0.89990234375,
          0.87060546875
        ],
        "bos_attention_strength": [
          1.0,
          0.95263671875,
          0.94287109375,
          0.88671875,
          0.87353515625,
          0.88720703125,
          0.8603515625,
          0.87939453125,
          0.80029296875,
          0.82275390625,
          0.8505859375,
          0.91650390625,
          0.79931640625,
          0.83056640625
        ],
        "attention_concentration": [
          1.0,
          0.95263671875,
          0.94287109375,
          0.88671875,
          0.87353515625,
          0.88720703125,
          0.8603515625,
          0.87939453125,
          0.80029296875,
          0.82275390625,
          0.8505859375,
          0.91650390625,
          0.79931640625,
          0.83056640625
        ]
      },
      {
        "layer": 4,
        "attention_entropy": [
          -0.0,
          0.306640625,
          0.388671875,
          0.630859375,
          0.662109375,
          0.72412109375,
          0.7177734375,
          0.71923828125,
          0.9189453125,
          1.078125,
          0.75,
          0.7880859375,
          0.68603515625,
          1.142578125
        ],
        "bos_attention_strength": [
          1.0,
          0.908203125,
          0.90185546875,
          0.833984375,
          0.83837890625,
          0.828125,
          0.8369140625,
          0.837890625,
          0.7939453125,
          0.75439453125,
          0.849609375,
          0.83056640625,
          0.8623046875,
          0.755859375
        ],
        "attention_concentration": [
          1.0,
          0.908203125,
          0.90185546875,
          0.833984375,
          0.83837890625,
          0.828125,
          0.8369140625,
          0.837890625,
          0.7939453125,
          0.75439453125,
          0.849609375,
          0.83056640625,
          0.8623046875,
          0.755859375
        ]
      },
      {
        "layer": 5,
        "attention_entropy": [
          -0.0,
          0.25341796875,
          0.394287109375,
          0.5341796875,
          0.5419921875,
          0.58740234375,
          0.62158203125,
          0.60498046875,
          0.9111328125,
          0.9580078125,
          0.869140625,
          0.75390625,
          0.8828125,
          0.99853515625
        ],
        "bos_attention_strength": [
          1.0,
          0.93017578125,
          0.89990234375,
          0.86572265625,
          0.87548828125,
          0.87158203125,
          0.8671875,
          0.87451171875,
          0.7978515625,
          0.79150390625,
          0.8212890625,
          0.84912109375,
          0.8154296875,
          0.79736328125
        ],
        "attention_concentration": [
          1.0,
          0.93017578125,
          0.89990234375,
          0.86572265625,
          0.87548828125,
          0.87158203125,
          0.8671875,
          0.87451171875,
          0.7978515625,
          0.79150390625,
          0.8212890625,
          0.84912109375,
          0.8154296875,
          0.79736328125
        ]
      },
      {
        "layer": 6,
        "attention_entropy": [
          -0.0,
          0.20166015625,
          0.478515625,
          0.63330078125,
          0.68310546875,
          0.5166015625,
          0.71337890625,
          0.9365234375,
          1.0185546875,
          1.16015625,
          1.0078125,
          0.81494140625,
          1.0400390625,
          1.3486328125
        ],
        "bos_attention_strength": [
          1.0,
          0.94873046875,
          0.86474609375,
          0.8330078125,
          0.83056640625,
          0.89111328125,
          0.837890625,
          0.77783203125,
          0.7666015625,
          0.7275390625,
          0.76806640625,
          0.8291015625,
          0.75830078125,
          0.6962890625
        ],
        "attention_concentration": [
          1.0,
          0.94873046875,
          0.86474609375,
          0.8330078125,
          0.83056640625,
          0.89111328125,
          0.837890625,
          0.77783203125,
          0.7666015625,
          0.7275390625,
          0.76806640625,
          0.8291015625,
          0.75830078125,
          0.6962890625
        ]
      },
      {
        "layer": 7,
        "attention_entropy": [
          -0.0,
          0.28515625,
          0.5966796875,
          0.6357421875,
          0.76220703125,
          0.8623046875,
          0.9833984375,
          1.1376953125,
          1.2548828125,
          1.3271484375,
          1.224609375,
          1.2080078125,
          1.3662109375,
          1.458984375
        ],
        "bos_attention_strength": [
          1.0,
          0.91748046875,
          0.81787109375,
          0.83154296875,
          0.80029296875,
          0.7822265625,
          0.7451171875,
          0.712890625,
          0.68310546875,
          0.67138671875,
          0.71240234375,
          0.72705078125,
          0.6552734375,
          0.66015625
        ],
        "attention_concentration": [
          1.0,
          0.91748046875,
          0.81787109375,
          0.83154296875,
          0.80029296875,
          0.7822265625,
          0.7451171875,
          0.712890625,
          0.68310546875,
          0.67138671875,
          0.71240234375,
          0.72705078125,
          0.6552734375,
          0.66015625
        ]
      },
      {
        "layer": 8,
        "attention_entropy": [
          -0.0,
          0.2457275390625,
          0.59033203125,
          0.7548828125,
          0.8388671875,
          0.7578125,
          0.8671875,
          1.08203125,
          1.2509765625,
          1.375,
          1.2353515625,
          1.2158203125,
          1.3134765625,
          1.5849609375
        ],
        "bos_attention_strength": [
          1.0,
          0.93310546875,
          0.82275390625,
          0.78515625,
          0.77392578125,
          0.81640625,
          0.7802734375,
          0.72412109375,
          0.68798828125,
          0.65625,
          0.7109375,
          0.71044921875,
          0.6630859375,
          0.6181640625
        ],
        "attention_concentration": [
          1.0,
          0.93310546875,
          0.82275390625,
          0.78515625,
          0.77392578125,
          0.81640625,
          0.7802734375,
          0.72412109375,
          0.68798828125,
          0.65625,
          0.7109375,
          0.71044921875,
          0.6630859375,
          0.6181640625
        ]
      },
      {
        "layer": 9,
        "attention_entropy": [
          -0.0,
          0.178955078125,
          0.501953125,
          0.6826171875,
          0.73095703125,
          0.83349609375,
          0.88134765625,
          1.1298828125,
          1.06640625,
          1.13671875,
          1.2216796875,
          1.212890625,
          1.427734375,
          1.4462890625
        ],
        "bos_attention_strength": [
          1.0,
          0.95654296875,
          0.859375,
          0.81103515625,
          0.806640625,
          0.7890625,
          0.77099609375,
          0.71240234375,
          0.75048828125,
          0.734375,
          0.70751953125,
          0.71533203125,
          0.640625,
          0.67041015625
        ],
        "attention_concentration": [
          1.0,
          0.95654296875,
          0.859375,
          0.81103515625,
          0.806640625,
          0.7890625,
          0.77099609375,
          0.71240234375,
          0.75048828125,
          0.734375,
          0.70751953125,
          0.71533203125,
          0.640625,
          0.67041015625
        ]
      },
      {
        "layer": 10,
        "attention_entropy": [
          -0.0,
          0.20947265625,
          0.4443359375,
          0.55615234375,
          0.6279296875,
          0.830078125,
          0.84521484375,
          1.0263671875,
          1.015625,
          1.0302734375,
          1.2275390625,
          1.2939453125,
          1.45703125,
          1.228515625
        ],
        "bos_attention_strength": [
          1.0,
          0.9462890625,
          0.88232421875,
          0.86083984375,
          0.84814453125,
          0.79150390625,
          0.78271484375,
          0.7470703125,
          0.7666015625,
          0.77001953125,
          0.71240234375,
          0.701171875,
          0.6494140625,
          0.734375
        ],
        "attention_concentration": [
          1.0,
          0.9462890625,
          0.88232421875,
          0.86083984375,
          0.84814453125,
          0.79150390625,
          0.78271484375,
          0.7470703125,
          0.7666015625,
          0.77001953125,
          0.71240234375,
          0.701171875,
          0.6494140625,
          0.734375
        ]
      },
      {
        "layer": 11,
        "attention_entropy": [
          -0.0,
          0.280029296875,
          0.64453125,
          0.75048828125,
          0.921875,
          0.95068359375,
          1.0478515625,
          1.30859375,
          1.443359375,
          1.4765625,
          1.37890625,
          1.2060546875,
          1.5849609375,
          1.9287109375
        ],
        "bos_attention_strength": [
          1.0,
          0.91943359375,
          0.79638671875,
          0.787109375,
          0.73876953125,
          0.75,
          0.7001953125,
          0.62890625,
          0.61328125,
          0.61474609375,
          0.6640625,
          0.7197265625,
          0.5830078125,
          0.50048828125
        ],
        "attention_concentration": [
          1.0,
          0.91943359375,
          0.79638671875,
          0.787109375,
          0.73876953125,
          0.75,
          0.7001953125,
          0.62890625,
          0.61328125,
          0.61474609375,
          0.6640625,
          0.7197265625,
          0.5830078125,
          0.50048828125
        ]
      },
      {
        "layer": 12,
        "attention_entropy": [
          -0.0,
          0.23095703125,
          0.4072265625,
          0.5888671875,
          0.70068359375,
          0.72216796875,
          0.79638671875,
          0.94384765625,
          1.0341796875,
          1.04296875,
          1.0087890625,
          0.72509765625,
          1.1201171875,
          1.5244140625
        ],
        "bos_attention_strength": [
          1.0,
          0.9384765625,
          0.89501953125,
          0.84716796875,
          0.8232421875,
          0.8271484375,
          0.81005859375,
          0.7744140625,
          0.759765625,
          0.763671875,
          0.78173828125,
          0.849609375,
          0.74609375,
          0.64794921875
        ],
        "attention_concentration": [
          1.0,
          0.9384765625,
          0.89501953125,
          0.84716796875,
          0.8232421875,
          0.8271484375,
          0.81005859375,
          0.7744140625,
          0.759765625,
          0.763671875,
          0.78173828125,
          0.849609375,
          0.74609375,
          0.64794921875
        ]
      },
      {
        "layer": 13,
        "attention_entropy": [
          -0.0,
          0.1964111328125,
          0.44384765625,
          0.67724609375,
          0.79052734375,
          0.81005859375,
          0.892578125,
          1.12109375,
          1.146484375,
          1.2333984375,
          1.1005859375,
          0.90771484375,
          1.2861328125,
          1.43359375
        ],
        "bos_attention_strength": [
          1.0,
          0.95068359375,
          0.88134765625,
          0.81640625,
          0.78955078125,
          0.80029296875,
          0.7705078125,
          0.712890625,
          0.720703125,
          0.7001953125,
          0.7490234375,
          0.7900390625,
          0.6767578125,
          0.671875
        ],
        "attention_concentration": [
          1.0,
          0.95068359375,
          0.88134765625,
          0.81640625,
          0.78955078125,
          0.80029296875,
          0.7705078125,
          0.712890625,
          0.720703125,
          0.7001953125,
          0.7490234375,
          0.7900390625,
          0.6767578125,
          0.671875
        ]
      },
      {
        "layer": 14,
        "attention_entropy": [
          -0.0,
          0.3505859375,
          0.6328125,
          0.74072265625,
          0.91455078125,
          0.86328125,
          0.93603515625,
          1.1943359375,
          1.2060546875,
          1.37890625,
          1.087890625,
          1.060546875,
          1.33203125,
          1.625
        ],
        "bos_attention_strength": [
          1.0,
          0.88818359375,
          0.802734375,
          0.7900390625,
          0.74365234375,
          0.775390625,
          0.751953125,
          0.68505859375,
          0.6982421875,
          0.6455078125,
          0.7490234375,
          0.73681640625,
          0.669921875,
          0.61083984375
        ],
        "attention_concentration": [
          1.0,
          0.88818359375,
          0.802734375,
          0.7900390625,
          0.74365234375,
          0.775390625,
          0.751953125,
          0.68505859375,
          0.6982421875,
          0.6455078125,
          0.7490234375,
          0.73681640625,
          0.669921875,
          0.61083984375
        ]
      },
      {
        "layer": 15,
        "attention_entropy": [
          -0.0,
          0.325439453125,
          0.5517578125,
          0.609375,
          0.951171875,
          0.8720703125,
          0.8564453125,
          1.1083984375,
          1.0263671875,
          1.1748046875,
          1.0283203125,
          0.93115234375,
          1.171875,
          1.451171875
        ],
        "bos_attention_strength": [
          1.0,
          0.89990234375,
          0.83935546875,
          0.837890625,
          0.72509765625,
          0.7783203125,
          0.78564453125,
          0.72412109375,
          0.7607421875,
          0.72265625,
          0.76220703125,
          0.77490234375,
          0.72216796875,
          0.6650390625
        ],
        "attention_concentration": [
          1.0,
          0.89990234375,
          0.83935546875,
          0.837890625,
          0.72509765625,
          0.7783203125,
          0.78564453125,
          0.72412109375,
          0.7607421875,
          0.72265625,
          0.76220703125,
          0.77490234375,
          0.72216796875,
          0.6650390625
        ]
      },
      {
        "layer": 16,
        "attention_entropy": [
          -0.0,
          0.1873779296875,
          0.3818359375,
          0.47216796875,
          0.62060546875,
          0.505859375,
          0.48095703125,
          0.7421875,
          0.6611328125,
          0.81787109375,
          0.457763671875,
          0.58740234375,
          0.81005859375,
          1.228515625
        ],
        "bos_attention_strength": [
          1.0,
          0.95361328125,
          0.90234375,
          0.88671875,
          0.849609375,
          0.890625,
          0.89892578125,
          0.8388671875,
          0.86376953125,
          0.82666015625,
          0.9140625,
          0.8701171875,
          0.81787109375,
          0.724609375
        ],
        "attention_concentration": [
          1.0,
          0.95361328125,
          0.90234375,
          0.88671875,
          0.849609375,
          0.890625,
          0.89892578125,
          0.8388671875,
          0.86376953125,
          0.82666015625,
          0.9140625,
          0.8701171875,
          0.81787109375,
          0.724609375
        ]
      },
      {
        "layer": 17,
        "attention_entropy": [
          -0.0,
          0.191650390625,
          0.37548828125,
          0.279052734375,
          0.51025390625,
          0.406982421875,
          0.41357421875,
          0.5615234375,
          0.67578125,
          0.7490234375,
          0.39208984375,
          0.52978515625,
          0.74853515625,
          1.0302734375
        ],
        "bos_attention_strength": [
          1.0,
          0.9521484375,
          0.90576171875,
          0.94287109375,
          0.8857421875,
          0.91650390625,
          0.91552734375,
          0.8857421875,
          0.859375,
          0.84521484375,
          0.9287109375,
          0.8984375,
          0.85107421875,
          0.78173828125
        ],
        "attention_concentration": [
          1.0,
          0.9521484375,
          0.90576171875,
          0.94287109375,
          0.8857421875,
          0.91650390625,
          0.91552734375,
          0.8857421875,
          0.859375,
          0.84521484375,
          0.9287109375,
          0.8984375,
          0.85107421875,
          0.78173828125
        ]
      },
      {
        "layer": 18,
        "attention_entropy": [
          -0.0,
          0.175537109375,
          0.3603515625,
          0.372802734375,
          0.60107421875,
          0.3935546875,
          0.327880859375,
          0.5205078125,
          0.72265625,
          0.74658203125,
          0.322509765625,
          0.472900390625,
          0.701171875,
          1.1005859375
        ],
        "bos_attention_strength": [
          1.0,
          0.95751953125,
          0.9091796875,
          0.91552734375,
          0.85595703125,
          0.9208984375,
          0.939453125,
          0.89892578125,
          0.84814453125,
          0.845703125,
          0.94482421875,
          0.908203125,
          0.8642578125,
          0.76513671875
        ],
        "attention_concentration": [
          1.0,
          0.95751953125,
          0.9091796875,
          0.91552734375,
          0.85595703125,
          0.9208984375,
          0.939453125,
          0.89892578125,
          0.84814453125,
          0.845703125,
          0.94482421875,
          0.908203125,
          0.8642578125,
          0.76513671875
        ]
      },
      {
        "layer": 19,
        "attention_entropy": [
          -0.0,
          0.254638671875,
          0.43798828125,
          0.5009765625,
          0.77685546875,
          0.5390625,
          0.65869140625,
          0.8857421875,
          0.71533203125,
          0.9228515625,
          0.48974609375,
          0.56591796875,
          0.6328125,
          0.78076171875
        ],
        "bos_attention_strength": [
          1.0,
          0.9296875,
          0.88427734375,
          0.8740234375,
          0.79296875,
          0.87548828125,
          0.8427734375,
          0.7861328125,
          0.8427734375,
          0.78125,
          0.90185546875,
          0.8779296875,
          0.87109375,
          0.84375
        ],
        "attention_concentration": [
          1.0,
          0.9296875,
          0.88427734375,
          0.8740234375,
          0.79296875,
          0.87548828125,
          0.8427734375,
          0.7861328125,
          0.8427734375,
          0.78125,
          0.90185546875,
          0.8779296875,
          0.87109375,
          0.84375
        ]
      },
      {
        "layer": 20,
        "attention_entropy": [
          -0.0,
          0.136962890625,
          0.2783203125,
          0.367919921875,
          0.6337890625,
          0.41162109375,
          0.490234375,
          0.65234375,
          0.5556640625,
          0.80859375,
          0.347900390625,
          0.4052734375,
          0.67236328125,
          0.919921875
        ],
        "bos_attention_strength": [
          1.0,
          0.96923828125,
          0.93701171875,
          0.9189453125,
          0.84765625,
          0.90771484375,
          0.8955078125,
          0.86474609375,
          0.89013671875,
          0.828125,
          0.9384765625,
          0.92578125,
          0.86865234375,
          0.80615234375
        ],
        "attention_concentration": [
          1.0,
          0.96923828125,
          0.93701171875,
          0.9189453125,
          0.84765625,
          0.90771484375,
          0.8955078125,
          0.86474609375,
          0.89013671875,
          0.828125,
          0.9384765625,
          0.92578125,
          0.86865234375,
          0.80615234375
        ]
      },
      {
        "layer": 21,
        "attention_entropy": [
          -0.0,
          0.192138671875,
          0.326171875,
          0.284912109375,
          0.34326171875,
          0.215087890625,
          0.27685546875,
          0.416259765625,
          0.6064453125,
          0.4951171875,
          0.21533203125,
          0.4521484375,
          0.65673828125,
          0.9384765625
        ],
        "bos_attention_strength": [
          1.0,
          0.9521484375,
          0.92236328125,
          0.94140625,
          0.931640625,
          0.96142578125,
          0.95068359375,
          0.92236328125,
          0.87744140625,
          0.9033203125,
          0.96533203125,
          0.9140625,
          0.875,
          0.8037109375
        ],
        "attention_concentration": [
          1.0,
          0.9521484375,
          0.92236328125,
          0.94140625,
          0.931640625,
          0.96142578125,
          0.95068359375,
          0.92236328125,
          0.87744140625,
          0.9033203125,
          0.96533203125,
          0.9140625,
          0.875,
          0.8037109375
        ]
      },
      {
        "layer": 22,
        "attention_entropy": [
          -0.0,
          0.19482421875,
          0.403076171875,
          0.32958984375,
          0.48095703125,
          0.299560546875,
          0.360595703125,
          0.498779296875,
          0.51025390625,
          0.355712890625,
          0.40234375,
          0.485595703125,
          0.52490234375,
          0.85498046875
        ],
        "bos_attention_strength": [
          1.0,
          0.951171875,
          0.89697265625,
          0.9296875,
          0.89306640625,
          0.9423828125,
          0.92822265625,
          0.90185546875,
          0.9013671875,
          0.93603515625,
          0.9111328125,
          0.90673828125,
          0.9052734375,
          0.818359375
        ],
        "attention_concentration": [
          1.0,
          0.951171875,
          0.89697265625,
          0.9296875,
          0.89306640625,
          0.9423828125,
          0.92822265625,
          0.90185546875,
          0.9013671875,
          0.93603515625,
          0.9111328125,
          0.90673828125,
          0.9052734375,
          0.818359375
        ]
      },
      {
        "layer": 23,
        "attention_entropy": [
          -0.0,
          0.193603515625,
          0.341552734375,
          0.3544921875,
          0.4755859375,
          0.416259765625,
          0.46630859375,
          0.74072265625,
          0.77294921875,
          0.626953125,
          0.434326171875,
          0.634765625,
          0.8740234375,
          1.0234375
        ],
        "bos_attention_strength": [
          1.0,
          0.95166015625,
          0.9169921875,
          0.919921875,
          0.89404296875,
          0.9111328125,
          0.90234375,
          0.837890625,
          0.82421875,
          0.86572265625,
          0.8935546875,
          0.8623046875,
          0.8115234375,
          0.77587890625
        ],
        "attention_concentration": [
          1.0,
          0.95166015625,
          0.9169921875,
          0.919921875,
          0.89404296875,
          0.9111328125,
          0.90234375,
          0.837890625,
          0.82421875,
          0.86572265625,
          0.8935546875,
          0.8623046875,
          0.8115234375,
          0.77587890625
        ]
      },
      {
        "layer": 24,
        "attention_entropy": [
          -0.0,
          0.26123046875,
          0.44287109375,
          0.423828125,
          0.46044921875,
          0.41552734375,
          0.441650390625,
          0.62109375,
          0.71630859375,
          0.4716796875,
          0.36474609375,
          0.6591796875,
          0.84814453125,
          1.0615234375
        ],
        "bos_attention_strength": [
          1.0,
          0.92724609375,
          0.88134765625,
          0.90185546875,
          0.8984375,
          0.91162109375,
          0.91015625,
          0.87158203125,
          0.84228515625,
          0.91162109375,
          0.92529296875,
          0.85986328125,
          0.82080078125,
          0.7607421875
        ],
        "attention_concentration": [
          1.0,
          0.92724609375,
          0.88134765625,
          0.90185546875,
          0.8984375,
          0.91162109375,
          0.91015625,
          0.87158203125,
          0.84228515625,
          0.91162109375,
          0.92529296875,
          0.85986328125,
          0.82080078125,
          0.7607421875
        ]
      },
      {
        "layer": 25,
        "attention_entropy": [
          -0.0,
          0.2890625,
          0.4248046875,
          0.486328125,
          0.44873046875,
          0.42041015625,
          0.52099609375,
          0.62109375,
          0.60400390625,
          0.51123046875,
          0.462158203125,
          0.59033203125,
          0.6748046875,
          0.6962890625
        ],
        "bos_attention_strength": [
          1.0,
          0.91552734375,
          0.88916015625,
          0.87744140625,
          0.90087890625,
          0.90771484375,
          0.876953125,
          0.86572265625,
          0.86669921875,
          0.89599609375,
          0.89697265625,
          0.87451171875,
          0.86279296875,
          0.85791015625
        ],
        "attention_concentration": [
          1.0,
          0.91552734375,
          0.88916015625,
          0.87744140625,
          0.90087890625,
          0.90771484375,
          0.876953125,
          0.86572265625,
          0.86669921875,
          0.89599609375,
          0.89697265625,
          0.87451171875,
          0.86279296875,
          0.85791015625
        ]
      },
      {
        "layer": 26,
        "attention_entropy": [
          -0.0,
          0.368408203125,
          0.61474609375,
          0.63720703125,
          0.81494140625,
          0.67138671875,
          0.74658203125,
          1.14453125,
          1.064453125,
          0.9599609375,
          0.63037109375,
          1.1298828125,
          1.302734375,
          1.4970703125
        ],
        "bos_attention_strength": [
          1.0,
          0.87939453125,
          0.80712890625,
          0.81640625,
          0.7724609375,
          0.83740234375,
          0.826171875,
          0.70263671875,
          0.72998046875,
          0.77099609375,
          0.8505859375,
          0.71337890625,
          0.6728515625,
          0.611328125
        ],
        "attention_concentration": [
          1.0,
          0.87939453125,
          0.80712890625,
          0.81640625,
          0.7724609375,
          0.83740234375,
          0.826171875,
          0.70263671875,
          0.72998046875,
          0.77099609375,
          0.8505859375,
          0.71337890625,
          0.6728515625,
          0.611328125
        ]
      },
      {
        "layer": 27,
        "attention_entropy": [
          -0.0,
          0.4443359375,
          0.71337890625,
          0.61865234375,
          0.86474609375,
          0.72998046875,
          0.8818359375,
          1.00390625,
          0.91455078125,
          0.85546875,
          0.732421875,
          1.0810546875,
          1.0439453125,
          1.16015625
        ],
        "bos_attention_strength": [
          1.0,
          0.83740234375,
          0.74072265625,
          0.81494140625,
          0.734375,
          0.79443359375,
          0.755859375,
          0.72802734375,
          0.755859375,
          0.77197265625,
          0.7763671875,
          0.70849609375,
          0.73583984375,
          0.67138671875
        ],
        "attention_concentration": [
          1.0,
          0.83740234375,
          0.74072265625,
          0.81494140625,
          0.734375,
          0.79443359375,
          0.755859375,
          0.72802734375,
          0.755859375,
          0.77197265625,
          0.7763671875,
          0.70849609375,
          0.73583984375,
          0.67138671875
        ]
      }
    ]
  }
}